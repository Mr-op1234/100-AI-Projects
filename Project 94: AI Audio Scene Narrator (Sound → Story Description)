Description:
This project creates an AI narrator that converts environmental audio into natural language scene descriptions ‚Äî like ‚ÄúA child is laughing while a car drives by in the background.‚Äù It combines sound tagging and caption generation.

Goal
Use environmental sound tagging + language generation to narrate a story-like description of what's happening in the audio scene.

Code (Prototype Concept)
import torch
import torchaudio
from transformers import AutoProcessor, AutoModelForSeq2SeqLM
 
# Step 1: Load a pretrained sound tagging model
tagger = torch.hub.load('qiuqiangkong/audioset_tagging_cnn', 'resnet38')
tagger.eval()
 
# Audio preprocessing
waveform, sr = torchaudio.load("data/city_scene.wav")
waveform = torchaudio.functional.resample(waveform, sr, 32000)
waveform = waveform[:, :32000]  # 1 second
mono_waveform = waveform.mean(dim=0).unsqueeze(0)
 
# Tag the audio (outputs AudioSet tags)
with torch.no_grad():
    tags = tagger(mono_waveform)
topk = torch.topk(tags, k=5).indices[0]
event_labels = [tagger.labels[i] for i in topk]
 
# Step 2: Construct prompt from tags
tag_phrase = ", ".join(event_labels)
prompt = f"Describe a scene where you hear: {tag_phrase}."
 
# Step 3: Use a text-to-text model for narration
processor = AutoProcessor.from_pretrained("google/flan-t5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")
 
inputs = processor(prompt, return_tensors="pt")
output = model.generate(**inputs, max_length=50)
narration = processor.batch_decode(output, skip_special_tokens=True)[0]
 
# Output
print("üîä Sound Tags:", event_labels)
print("\nüìñ Scene Narration:", narration)
Example Output
Sound Tags: ['car passing', 'children playing', 'dog bark', 'street music', 'horn']
Scene Narration: A lively street where children are playing and dogs are barking as cars pass by.
